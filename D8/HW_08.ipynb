{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV as HRSCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from project_module import regression_report\n",
    "from project_module.feature_selection import SelectKBestByCoefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 89) (1095,) (365, 89) (365,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解題步驟：\n",
    "\n",
    "1. 讀取 x_train.npy, y_train.npy, x_test.npy, y_test.npy\n",
    "2. 先以上課的知識或 default hyperparameter 調整出一個不會 over-fitting 太多的 XGBoost 模型\n",
    "3. 以該組超參數為基準，搜尋附近的參數(可以用自己偏好的搜尋策略)\n",
    "4. 將最終調整結果與一開始的模型做比較，誤差是否有降低\n",
    "5. 請比較 Random Forest, XGBoost(有時間的同學可以增加 GBDT, Adaboost) 的超參數搜尋時間與誤差(記得要控制 n_estimators 等會影響到時間的參數，使其叫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"ambda\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "mse = 1031206072.6127\n",
      "mae = 17231.6043\n",
      "rmse = 32112.3975\n",
      "mape = 0.0954\n"
     ]
    }
   ],
   "source": [
    "def get_XGBR(params: dict) -> XGBRegressor:\n",
    "    XGBR = XGBRegressor(**params)\n",
    "    return XGBR\n",
    "\n",
    "best_params = {\n",
    "    'eta':0.3, 'gamma':0, 'max_depth':6, 'ambda':1, 'alpha':0,\n",
    "    'max_depth':6, 'min_child_weight':4, 'subsample':1,\n",
    "    'objective':'reg:squarederror', 'scale_pos_weight':1,\n",
    "    'colsample_bytree':1, 'colsample_bylevel':1, 'colsample_bynode':1,\n",
    "}\n",
    "\n",
    "XGBR = get_XGBR(best_params)\n",
    "XGBR.fit(x_train, y_train)\n",
    "\n",
    "pred = XGBR.predict(x_test)\n",
    "regression_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [XGBoost 官方文檔](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "\n",
    "## 計算 XGBoost 超參數搜尋時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRSCV ended in 122.0842s\n",
      "\n",
      "Best score is 0.1006\n",
      "Best params is {'subsample': 0.76, 'objective': 'reg:squarederror', 'n_estimators': 192, 'min_child_weight': 0.6370665120808605, 'max_depth': 5, 'lambda': 0.56, 'eta': 0.02573989947635369, 'alpha': 0.41000000000000003}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 搜尋超參數，並計算搜尋時間 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 XGBoost 單輪訓練時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost was trained in 0.2171s\n",
      "\n",
      "mse = 1010869446.2126\n",
      "mae = 15842.4891\n",
      "rmse = 31794.1731\n",
      "mape = 0.0904\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 使用搜尋到的參數分析在 testing data 上的誤差表現，並計算時間 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 Random Forest 超參數搜尋時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here: 搜尋 Random Forest 超參數，並計算搜尋時間 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 Random Forest 單輪訓練時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest was trained in 0.1777s\n",
      "\n",
      "mse = 1192438196.9586\n",
      "mae = 18699.1861\n",
      "rmse = 34531.6984\n",
      "mape = 0.1060\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 使用搜尋到的參數分析在 testing data 上的誤差表現，並計算時間 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
